{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Torch.Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch._dynamo as dynamo\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2838]], grad_fn=<CompiledFunctionBackward>)\n"
     ]
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel()\n",
    "\n",
    "# Compile the model\n",
    "compiled_model = torch.compile(model)\n",
    "\n",
    "# Use the compiled model as you would normally\n",
    "input_data = torch.randn(1, 10)\n",
    "output = compiled_model(input_data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'nvfuser' is optimized for NVIDIA GPUs\n",
    "compiled_model = torch.compile(model, backend='nvfuser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profiling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janhsc/miniconda3/envs/MachineLearning/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:764: UserWarning: explain(f, *args, **kwargs) is deprecated, use explain(f)(*args, **kwargs) instead.  If you don't migrate, we may break your explain call in the future if your user defined kwargs conflict with future kwargs added to explain(f).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExplainOutput(graphs=[GraphModule(\n",
       "  (L__self___fc1): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (L__self___relu): ReLU()\n",
       "  (L__self___fc2): Linear(in_features=10, out_features=1, bias=True)\n",
       ")], graph_count=1, graph_break_count=0, break_reasons=[], op_count=0, ops_per_graph=[[]], out_guards=[\n",
       "        shape_env '' SHAPE_ENV\n",
       "        {\n",
       "            'guard_types': None,\n",
       "            'code': None,\n",
       "            'obj_weakref': None\n",
       "            'guarded_class': None\n",
       "        }\n",
       "        , \n",
       "        global '' TORCH_FUNCTION_STATE\n",
       "        {\n",
       "            'guard_types': None,\n",
       "            'code': None,\n",
       "            'obj_weakref': None\n",
       "            'guarded_class': None\n",
       "        }\n",
       "        , \n",
       "        local_nn_module \"L['self'].fc1\" NN_MODULE\n",
       "        {\n",
       "            'guard_types': None,\n",
       "            'code': None,\n",
       "            'obj_weakref': None\n",
       "            'guarded_class': None\n",
       "        }\n",
       "        , \n",
       "        local_nn_module \"L['self'].relu\" NN_MODULE\n",
       "        {\n",
       "            'guard_types': None,\n",
       "            'code': None,\n",
       "            'obj_weakref': None\n",
       "            'guarded_class': None\n",
       "        }\n",
       "        , \n",
       "        global '' DEFAULT_DEVICE\n",
       "        {\n",
       "            'guard_types': ['DEFAULT_DEVICE'],\n",
       "            'code': ['utils_device.CURRENT_DEVICE == None'],\n",
       "            'obj_weakref': None\n",
       "            'guarded_class': None\n",
       "        }\n",
       "        , \n",
       "        local_nn_module \"L['self'].fc2\" NN_MODULE\n",
       "        {\n",
       "            'guard_types': None,\n",
       "            'code': None,\n",
       "            'obj_weakref': None\n",
       "            'guarded_class': None\n",
       "        }\n",
       "        , \n",
       "        global '' BACKEND_MATCH\n",
       "        {\n",
       "            'guard_types': ['BACKEND_MATCH'],\n",
       "            'code': ['___check_current_backend(139951735205760)'],\n",
       "            'obj_weakref': None\n",
       "            'guarded_class': None\n",
       "        }\n",
       "        , \n",
       "        global '' GRAD_MODE\n",
       "        {\n",
       "            'guard_types': None,\n",
       "            'code': None,\n",
       "            'obj_weakref': None\n",
       "            'guarded_class': None\n",
       "        }\n",
       "        , \n",
       "        local \"L['x']\" TENSOR_MATCH\n",
       "        {\n",
       "            'guard_types': ['TENSOR_MATCH'],\n",
       "            'code': [\"hasattr(L['x'], '_dynamo_dynamic_indices') == False\"],\n",
       "            'obj_weakref': <weakref at 0x7f48f9a01c10; dead>\n",
       "            'guarded_class': <weakref at 0x7f4983411580; to 'torch._C._TensorMeta' at 0x5b1ef60 (Tensor)>\n",
       "        }\n",
       "        , \n",
       "        global '' DETERMINISTIC_ALGORITHMS\n",
       "        {\n",
       "            'guard_types': None,\n",
       "            'code': None,\n",
       "            'obj_weakref': None\n",
       "            'guarded_class': None\n",
       "        }\n",
       "        , \n",
       "        local \"L['self']\" NN_MODULE\n",
       "        {\n",
       "            'guard_types': ['ID_MATCH'],\n",
       "            'code': [\"___check_obj_id(L['self'], 139955606737664)\"],\n",
       "            'obj_weakref': <weakref at 0x7f49015d8310; to 'MyModel' at 0x7f49f4395300>\n",
       "            'guarded_class': <weakref at 0x7f49f4399580; to 'type' at 0x20267f0 (MyModel)>\n",
       "        }\n",
       "        ], compile_times='TorchDynamo compilation metrics:\\nFunction                           Runtimes (s)\\n-------------------------------  --------------\\n_compile.<locals>.compile_inner          0.0104\\nOutputGraph.call_user_compiler           0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model and explain the compilation process\n",
    "compiled_model = torch.compile(model)\n",
    "dynamo.explain(compiled_model, torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_graph.png'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = torch.randn(1, 10)\n",
    "output = model(input_data)\n",
    "\n",
    "# Visualize the computational graph\n",
    "dot = make_dot(output, params=dict(list(model.named_parameters()) + [('input', input_data)]))\n",
    "dot.render(\"model_graph\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often useful to only compile part of the model to reduce overhead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2673, -0.0399,  0.2411, -0.4851,  0.2301,  0.1615,  0.4815,  0.4151,\n",
       "         -0.3506,  0.2458]], grad_fn=<CompiledFunctionBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling only part of a model\n",
    "class PartModel(nn.Module):\n",
    "    def __init__(self, model_part):\n",
    "        super(PartModel, self).__init__()\n",
    "        self.model_part = torch.compile(model_part)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model_part(x)\n",
    "\n",
    "compiled_model_part = PartModel(model.fc1)\n",
    "output = compiled_model_part(input_data)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An actual example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Compiling only the convolutional layers\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv_layers = torch.compile(nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.ReLU(),\n",
    "        ))\n",
    "        self.lstm = nn.LSTM(64, 128)\n",
    "        self.fc = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
