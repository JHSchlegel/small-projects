{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM by Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torchmetrics import MeanAbsoluteError\n",
    "from torch.utils.data import Dataset\n",
    "import optuna\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimpy import clean_columns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "import pytorch_lightning as L\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "%load_ext blackcellmagic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [video](https://www.youtube.com/watch?v=RHGiXPuo_pI&t=1794s&ab_channel=StatQuestwithJoshStarmer) shows how to implement LSTM models by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMbyHand(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(LSTMbyHand, self).__init__()\n",
    "        mean = torch.tensor(0.0)\n",
    "        std = torch.tensor(1.0)\n",
    "\n",
    "        self.wlr1 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.wlr2 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.blr1 = nn.Parameter(torch.tensor(0.0), requires_grad=True)\n",
    "\n",
    "        self.wpr1 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.wpr2 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.bpr1 = nn.Parameter(torch.tensor(0.0), requires_grad=True)\n",
    "\n",
    "        self.wp1 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.wp2 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.bp1 = nn.Parameter(torch.tensor(0.0), requires_grad=True)\n",
    "\n",
    "        self.wo1 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.wo2 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.bo1 = nn.Parameter(torch.tensor(0.0), requires_grad=True)\n",
    "\n",
    "    def lstm_unit(self, input_value, long_memory, short_memory):\n",
    "        long_remember_percent = torch.sigmoid(\n",
    "            (short_memory * self.wlr1) + (input_value * self.wlr2) + self.blr1\n",
    "        )\n",
    "\n",
    "        potential_remember_percent = torch.sigmoid(\n",
    "            (short_memory * self.wpr1) + (input_value * self.wpr2) + self.bpr1\n",
    "        )\n",
    "\n",
    "        potential_memory = torch.tanh(\n",
    "            (short_memory * self.wp1) + (input_value * self.wp2) + self.bp1\n",
    "        )\n",
    "\n",
    "        updated_long_memory = (long_memory * long_remember_percent) + (\n",
    "            potential_remember_percent * potential_memory\n",
    "        )\n",
    "\n",
    "        output_percent = torch.sigmoid(\n",
    "            (short_memory * self.wo1) + (input_value * self.wo2) + self.bo1\n",
    "        )\n",
    "\n",
    "        updated_short_memory = torch.tanh(updated_long_memory) * output_percent\n",
    "\n",
    "        return updated_long_memory, updated_short_memory\n",
    "\n",
    "    def forward(self, input):\n",
    "        long_memory = 0\n",
    "        short_memory = 0\n",
    "        day1 = input[0]\n",
    "        day2 = input[1]\n",
    "        day3 = input[2]\n",
    "        day4 = input[3]\n",
    "\n",
    "        long_memory, short_memory = self.lstm_unit(day1, long_memory, short_memory)\n",
    "        long_memory, short_memory = self.lstm_unit(day2, long_memory, short_memory)\n",
    "        long_memory, short_memory = self.lstm_unit(day3, long_memory, short_memory)\n",
    "        long_memory, short_memory = self.lstm_unit(day4, long_memory, short_memory)\n",
    "\n",
    "        return short_memory\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters())\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_i, label_i = batch\n",
    "        output_i = self.forward(input_i[0])\n",
    "        loss = (output_i - label_i) ** 2\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "\n",
    "        # log for first company\n",
    "        if label_i == 0:\n",
    "            self.log(\"out_0\", output_i)\n",
    "        # log for second company\n",
    "        else:\n",
    "            self.log(\"out_1\", output_i)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "model = LSTMbyHand()\n",
    "\n",
    "# create input data for the two companies\n",
    "inputs = torch.tensor([[0., 0.5, 0.25, 1.], [1., 0.5, 0.25, 1.]])\n",
    "labels = torch.tensor([0., 1.])\n",
    "\n",
    "# create tensor dataset\n",
    "dataset = TensorDataset(inputs, labels)\n",
    "dataloader = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(max_epochs = 2000)\n",
    "trainer.fit(model, train_dataloaders=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_best_checkpoint = trainer.checkpoint_callback.best_model_path\n",
    "\n",
    "trainer = L.Trainer(max_epochs=3000)\n",
    "trainer.fit(model, train_dataloaders=dataloader, ckpt_path=path_to_best_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Company A: Observed = 0, Predicted = {model(torch.tensor([0., 0.5, 0.25, 1.])).detach()}\"\n",
    ")  # detach gradients\n",
    "print(\n",
    "    f\"Company B: Observed = 1, Predicted = {model(torch.tensor([1., 0.5, 0.25, 1.])).detach()}\"\n",
    ")  # detach gradients"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
