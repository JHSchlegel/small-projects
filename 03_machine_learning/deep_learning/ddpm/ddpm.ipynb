{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion Model from Scratch in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on [this](https://towardsdatascience.com/diffusion-model-from-scratch-in-pytorch-ddpm-9d9760528946) TowardsDataScience article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages and Presets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange \n",
    "from typing import List\n",
    "import random\n",
    "import math\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader \n",
    "from timm.utils import ModelEmaV3 \n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diffusion Model Training\n",
    "**Input:** Training data x\n",
    "\n",
    "**Output:** Model parameters $\\phi_t$\n",
    "\n",
    "**repeat**\n",
    "\n",
    "> for $i\\in \\mathcal{B}$ do # for every training index in batch\n",
    ">> $t \\sim \\mathcal{U}(\\{1, ..., T\\})$ # sample a time step\n",
    "\n",
    ">> $\\varepsilon \\sim \\mathcal{N}(0, I)$ # sample noise  \n",
    "\n",
    ">> $\\ell_i = \\|g_t(\\sqrt{\\alpha_t} x_i + \\sqrt{1-\\alpha_t}\\varepsilon\\phi_t) - \\varepsilon \\|^2$ # individual loss\n",
    "\n",
    "> Acucmulate loses for batch and take gradient step\n",
    "\n",
    "**until converged**\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling from Diffusion Model\n",
    "**Input:** Model $g_t(\\cdot, \\phi_t)$\n",
    "\n",
    "**Output:** Sample $x$\n",
    "\n",
    "$z_T \\sim \\mathcal{N}(0, I)$ # sample last latent variable\n",
    "\n",
    "for $t = T, ..., 2$ do\n",
    "> $\\hat{z}_{t-1} = \\dfrac{1}{\\sqrt{1-\\beta_t}}z_t - \\dfrac{\\beta_t}{\\sqrt{1-\\alpha_t}\\sqrt{1-\\beta_t}}g_t(z_t, \\phi_t)$ # predict previous latent variable\n",
    "\n",
    "> $\\varepsilon \\sim \\mathcal{N}(0, I)$\n",
    "\n",
    "> $z_{t-1} = \\hat{z}_{t-1} + \\sqrt{\\sigma_t}\\varepsilon$ # add noise to previous altent variable\n",
    "\n",
    "$x = \\dfrac{1}{\\sqrt{1-\\beta_1}}z_1 - \\dfrac{\\beta_1}{\\sqrt{1-\\alpha_1}\\sqrt{1-\\alpha_1}}g_1(z_1, \\phi_1)$ # sample from z1 without noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, we add back a small amount of noise to the final sample to prevent mode collapse/ keep the process stable after having subtracted the estimated noise previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For predicting the noise for the diffusion reverse process, a special UNET is used that features attention in the 16x16 resolution and sinusoidal transformer embeddings in every residual block. The sinusoidal embeddings are used to encode for which time step the model is trying to predict the noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNET Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sinusoidal Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalEmbeddings(nn.Module):\n",
    "    def __init__(self, time_steps:int, embed_dim: int):\n",
    "        super().__init__()\n",
    "        position = torch.arange(time_steps).unsqueeze(1).float()\n",
    "        # scaling factor for the sinusoidal embeddings\n",
    "        div = torch.exp(torch.arange(0, embed_dim, 2).float() * -(math.log(10000.0) / embed_dim))\n",
    "        embeddings = torch.zeros(time_steps, embed_dim, requires_grad=False)\n",
    "        # sin for evend indices\n",
    "        embeddings[:, 0::2] = torch.sin(position * div)\n",
    "        # cos for odd indices\n",
    "        embeddings[:, 1::2] = torch.cos(position * div)\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        embeds = self.embeddings[t].to(x.device)\n",
    "        return embeds[:, :, None, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, C: int, num_groups: int, dropout_prob: float) -> None:\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.gnorm1 = nn.GroupNorm(num_groups=num_groups, num_channels=C)\n",
    "        self.gnorm2 = nn.GroupNorm(num_groups=num_groups, num_channels=C)\n",
    "        self.conv1 = nn.Conv2d(C, C, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(C, C, kernel_size=3, padding=1)\n",
    "        self.dropout = nn.Dropout(p = dropout_prob, inplace=True)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, embeddings: torch.Tensor)->torch.Tensor:\n",
    "        # add positional embeddings to the input\n",
    "        x = x + embeddings[:, :x.shape[1], :, :]\n",
    "        # output of the residual block\n",
    "        r = self.conv1(self.relu(self.gnorm1(x)))\n",
    "        r = self.dropout(r)\n",
    "        r = self.conv2(self.relu(self.gnorm2(r)))\n",
    "        return x + r # add the residual to the input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, C: int, num_heads: int, dropout_prob: float):\n",
    "        super().__init__()\n",
    "        self.proj1 = nn.Linear(C, C * 3)\n",
    "        self.proj2 = nn.Linear(C, C)\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout_prob = dropout_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        h, w = x.shape[2:]\n",
    "        x = rearrange(x, \"b c h w -> b (h w ) c\")\n",
    "        x = self.proj1(x)\n",
    "        x = rearrange(x, \"b L (C H K) -> K b H L C\", K=3, H=self.num_heads)\n",
    "        q, k, v = x[0], x[1], x[2]\n",
    "        x = F.scaled_dot_product_attention(\n",
    "            q, k, v, dropout_prob=self.dropout_prob, is_causal=False\n",
    "        )\n",
    "        x = rearrange(x, \"b H (h w) C -> b h w (C H)\", h=h, w=w)\n",
    "        x = self.proj2(x)\n",
    "        return rearrange(x, \"b h w C -> b C h w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNET Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNETLayer(nn.Module):\n",
    "    def __init__(self, \n",
    "            upscale: bool, \n",
    "            attention: bool, \n",
    "            num_groups: int, \n",
    "            dropout_prob: float,\n",
    "            num_heads: int,\n",
    "            C: int):\n",
    "        super().__init__()\n",
    "        self.resblock1 = ResidualBlock(C, num_groups, dropout_prob)\n",
    "        self.resblock2 = ResidualBlock(C, num_groups, dropout_prob)\n",
    "        \n",
    "        if upscale:\n",
    "            self.conv = nn.Conv2dTranspose2d(C, C//2, kernel_size=4, stride=2, padding=1)\n",
    "        else:\n",
    "            self.conv = nn.Conv2d(C, C*2, kernel_size=3, stride = 2, padding=1)\n",
    "        if attention:\n",
    "            self.attention = Attention(C, num_heads, dropout_prob)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, embeddings: torch.Tensor)->torch.Tensor:\n",
    "        x = self.resblock1(x, embeddings)\n",
    "        if hasattr(self, \"attention\"):\n",
    "            x = self.attention(x)\n",
    "        x = self.resblock2(x, embeddings)\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
